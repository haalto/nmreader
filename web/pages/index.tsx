import type { NextPage } from "next";
import Head from "next/head";
import { useEffect, useRef, useState } from "react";
import { createWorker } from "tesseract.js";
import { preProcessImg } from "../preprocessing/preprocessing";
const worker = createWorker();

const Home: NextPage = () => {
  const streamRef = useRef<MediaStream>();
  const videoRef = useRef<HTMLVideoElement>();
  const imgRef = useRef<HTMLCanvasElement>();
  const [text, setText] = useState("TEST");
  console.log(text);
  useEffect(() => {
    if (videoRef && videoRef.current) {
      navigator.mediaDevices
        .getUserMedia({
          video: { facingMode: "environment" },
          audio: false,
        })
        .then((stream) => {
          if (videoRef && videoRef.current) {
            videoRef.current.srcObject = stream;
          }

          streamRef.current = stream;

          stream.getVideoTracks().forEach((track) => {
            console.log(track);
          });

          const foo = async () => {
            await worker.load();
            await worker.loadLanguage("eng");
            await worker.initialize("eng");
            requestAnimationFrame(tick);
          };

          foo();
        })
        .catch((err) => {
          console.error(err);
        });
    }

    return () =>
      streamRef &&
      streamRef.current &&
      streamRef.current.getTracks().forEach((x) => x.stop());

    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  const tick = async () => {
    setTimeout(async () => {
      if (streamRef && streamRef.current && imgRef && imgRef.current) {
        // canvas
        const canvas = imgRef.current;
        const c = document.createElement("canvas");
        c.width = 500;
        c.height = 375;
        canvas.width = 500;
        canvas.height = 375;
        const image = videoRef.current;

        if (image) {
          //c?.getContext("2d")?.clearRect(0, 0, canvas.width, canvas.height);
          c?.getContext("2d")?.drawImage(image, 0, 0);
          const imgData = preProcessImg(c)
            .getCanvas()
            .getContext("2d")
            ?.getImageData(0, 0, 500, 375);

          canvas?.getContext("2d")?.putImageData(imgData as ImageData, 150, 0);
        }

        // tesseract
        const {
          data: { text },
        } = await worker.recognize(canvas);
        const regex = /[0-9]/gi;
        const scannedText = text.match(regex);

        if (scannedText) {
          //console.log(scannedText.join(""));
          setText(scannedText.join(""));
        }

        requestAnimationFrame(tick);
      }
    }, 100);
  };

  return (
    <div>
      <Head>
        <title>Create Next App</title>
        <meta name="description" content="Generated by create next app" />
        <link rel="icon" href="/favicon.ico" />
      </Head>
      <main>
        {videoRef && (
          <video
            ref={videoRef as React.Ref<HTMLVideoElement>}
            autoPlay
            muted
            playsInline
            width={500}
            height={500}
            style={{
              position: "absolute",
              top: 100,
              left: 0,
              zIndex: 2,
            }}
          ></video>
        )}
        {imgRef && (
          <canvas
            ref={imgRef as React.Ref<HTMLCanvasElement>}
            style={{
              position: "absolute",
              top: 500,
              left: 0,
              zIndex: 3,
            }}
          ></canvas>
        )}
        <div
          style={{
            width: 180,
            height: 80,
            border: "1px red solid",
            zIndex: 3,
            position: "absolute",
            top: 225,
            left: 150,
          }}
        ></div>
        <h1 className="text-xl text-center bg-red-200 font-bold mt-11">
          {text}
        </h1>
      </main>
    </div>
  );
};

export default Home;
